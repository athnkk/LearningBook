# 2.live555安装
- [编译安装](#1)
- [live555使用](#2)
- [源码分析](#3)

参考链接：  
1.编译安装  
https://blog.csdn.net/aobai219/article/details/5841951

## <a id="1">编译安装与测试</a>
- 1、编译安装  
下载源码下，解压。  
./genMakefiles linux-64bit     
make  
make install   

- 2、运行  
cd mediaServer  
./live555MediaServer。各种测试代码在testProg目录下。如果没出什么错的话，那么恭喜你安装成功！  
安装成功时，会在当前目录生成一个mediaServer文件夹。    

- 3.测试  
cd mediaServer  ，./live555MediaServer。请先打开配置防火墙打开端口 554 和 8000 ，如果是云服务器，请注意云服务器供应商是否有安全组等设置，也需要到安全组配置端口的。下面上传文件到live555MediaServer同级目录。

## <a id="2">live555使用</a>
- [openRTSP](#2.1)
- [live555MediaServer](#2.2)
- [testRTSPClient](#2.3)      


参考链接：  
1.live555中openRTSP用法  
https://www.cnblogs.com/lifan3a/articles/7284204.html  

### <a id="2.1">openRTSP</a>
参考链接：  
1.官方链接  
http://www.live555.com/openRTSP/  

openRTSP  
openRTSP是一个命令行程序，它可以用来打开，流化，接收并且录制指定的RTSP视频链接媒体流(如rtsp://开头的URL)。(一个相关的程序“playSIP”可以用来播放或者录制一个SIP会话)。  
```shell
Basic operation  基本操作
Playing without receiving 播放不接收
Playing-time options 播放时选项
Streaming access-controlled sessions 流式访问控制选项
Outputting a ".mov", ".mp4", or ".avi"-format file 输出一个mov, mp4, avi 格式文件
Periodic file output  周期的文件输出
'Trick play' options “特技播放”选项
Other options  其他选项
A note about RealAudio and RealVideo sessions 关于RealVideo和RealAudio会话注意事项
Source code  源码
Support and customization 支持与定制
Summary of command-line options 选项汇总

Summary of command-line options
(for "openRTSP" and "playSIP")
-4 output a '.mp4'-format file (to 'stdout', unless the "-P <interval-in-seconds>" option is also given)
输出一个“mp4”格式文件（到'标准输出'，除非同时有选项“-P <interval-in-seconds>”给定区间时间间隔）

-a play only the audio stream (to 'stdout', unless the "-P <interval-in-seconds>" option is also given)
只输出音频流（到'标准输出'，除非同时有选项“-P <interval-in-seconds>”给定区间时间间隔）

-A <codec-number> specify the static RTP payload format number of the audio codec to request from the server 
("playSIP" only)
指定从服务器请求的音频编解码器的静态RTP负载格式数量（仅用于“playSIP”）

-b <buffer-size> change the output file buffer size
更改输出文件的缓冲区大小 

-B <buffer-size> change the input network socket buffer size
更改输入网络套接字缓冲区大小

-c play continuously
连续播放 

-C Explicitly ask for a multicast stream even if the server's "DESCRIBE" response doesn't specify a multicast address. (Note that not all servers will support this.) ("openRTSP" only)
明确要求多播流，即使服务器的“DESCRIBE”响应不指定多播地址。（注意，并非所有的服务器都将支持此功能。）（仅对于“openRTSP”）

-d <duration>  specify an explicit duration
指定一个明确的持续时间

-D <maximum-inter-packet-gap> specify a maximum period of inactivity to wait before exiting
指定退出之前要等待的最长非活动状态时间

-f <frame-rate> specify the video frame rate (used only with "-q", "-4", or "-i")
指定的视频帧速率（仅用于“-q”，“-4”或“ -i”）

-F <fileName-prefix> specify a prefix for each output file name
指定每个输出文件名前缀

-g <user-agent-name> specify a user agent name to use in outgoing requests
指定输出请求中使用的用户代理名

-h <height>  specify the video image height (used only with "-q", "-4", or "-i")
指定视频图像的高度（仅用于“-q”，“-4”或“ -i”）

-H output a QuickTime 'hint track' for each audio/video track (used only with "-q" or "-4")
为每个音频/视频轨道输出QuickTime的“索引轨道”

-i output a '.avi'-format file (to 'stdout', unless the "-P <interval-in-seconds>" option is also given)
输出一个“avi”格式文件（到'标准输出'，除非同时有选项“-P <interval-in-seconds>”给定区间时间间隔）

-I <interface-name-or-address> specify a particular network interface on which to receive data
指定要接收数据的特定网络接口

-k <username> <password> specify a user name and password thats required to authenticate an incoming "REGISTER" command (used with "-R" only)
指定验证到来的“REGISTER”命令需要的用户名和密码（仅和“-R”使用） 

-l try to compensate for packet losses (used only with "-q", "-4", or "-i")
尽量弥补丢包（仅和“-q”，“-4”或“ - i”使用）

-m output each incoming frame into a separate file
输出的每个到来的帧到一个单独的文件

-M <MIME-subtype> specify the MIME subtype of a dynamic RTP payload format for the audio codec to request from the server ("playSIP" only)
为音频编解码器指定一个动态的RTP负载格式的MIME子类型来请求服务器（仅用于“playSIP”）

-n be notified when RTP data packets start arriving
RTP数据包到达时通知

-o request the servers command options, without sending "DESCRIBE" ("openRTSP" only)
请求服务器的命令选项，而不发送“DESCRIBE”（仅用于“openRTSP”）

-O dont request the servers command options; just send "DESCRIBE" ("openRTSP" only)
不请求服务器的命令选项;只要发送“DESCRIBE”（仅用于“openRTSP”）

-p <starting-port-number> specify the client port number(s)
指定客户端的端口号

-P <interval-in-seconds> write new output files every <interval-in-seconds> seconds
每一个时间区间写新的输出文件

-q output a QuickTime '.mov'-format file (to 'stdout', unless the "-P <interval-in-seconds>" option is also given)
输出一个“.mov”格式文件（到'标准输出'，除非同时有选项“-P <interval-in-seconds>”给定区间时间间隔）

-Q output 'QOS' statistics about the data stream (when the program exits)
输出关于数据流统计的QoS“（程序退出时）

-r play the RTP streams, but dont receive them
播放RTP流，但不接收他们

-R (or -R <port-number>) Waits for an incoming "REGISTER" command, specifying a "rtsp://" URL to play. This option is used instead of a "rtsp://" URL on the command line. ("openRTSP" only)
等待到来的“注册”命令，指定要播放端口号. 这个选项是用来代替命令行中的“rtsp://”URL。 （仅用于“openRTSP”）

-s <initial-seek-time> request that the server seek to the specified time (in seconds) before streaming
请求服务器在流化前搜索到指定的时间（以秒为单位） 用于“trick play”

-S <byte-offset> assume a simple RTP payload format (skipping over a special header of the specified size)
假设一个简单的RTP负载格式（跳过指定大小的特殊头）

-t stream RTP/RTCP data over TCP, rather than (the usual) UDP. ("openRTSP" only)
通过TCP流化RTP / RTCP数据，而不是通过（通常的）的UDP。 （仅用于“openRTSP”） 

-T <http-port-number> like "-t", except using RTSP-over-HTTP tunneling. ("openRTSP" only)
类似“-t”，除了使用RTSP-over-HTTP隧道。 （仅用于“openRTSP”） 

-u <username> <password> specify a user name and password for digest authentication
指定摘要式身份验证的用户名和密码 

-U <initial-absolute-seek-time> request that the server seek to the specified absolute time (format: "YYYYMMDDTHHMMSSZ" or "YYYYMMDDTHHMMSS.<frac>Z") before streaming
请求服务器在流化前搜索到指定的绝对时间

-v play only the video stream (to 'stdout', unless the "-P <interval-in-seconds>" option is also given)
只输出视频流（到'标准输出'，除非同时有选项“-P <interval-in-seconds>”给定区间时间间隔）

-V print less verbose diagnostic output
打印更加简洁诊断输出 

-w <width>  specify the video image width (used only with "-q", "-4", or "-i")
指定视频图像的宽度

-y try to synchronize the audio and video tracks (used only with "-q" or "-4")
尝试同步音频和视频轨道

-z <scale>  request that the server scale the stream (fast-forward, slow, or reverse play)
请求服务器缩放数据流（快进，慢速，或者反向播放）
```

比如：  
openRTSP -4 -d 15 rtsp://athnkk:athnkk@139.196.137.60/20190329203822_hint.mp4 >./a.mp4 

### <a id="2.2">live555MediaServer</a>
live555服务端程序，编译后在mediaServer目录下，make install安装后可以直接运行，在运行程序的目录下添加264文件，就可以完成点播了。播放地址为：   
rtsp://139.196.137.60:8554/yd.264    

### <a id="2.3">testRTSPClient</a>
live555客户端程序，编译后在testProgs目录下，make install安装后可以直接运行，运行如下：  
testRTSPClient rtsp://139.196.137.60:8554/yd.264   

## <a id="3">源码分析</a>
参考链接：   
1.Live555流程分析  
https://blog.csdn.net/u013898698/article/details/56284534?locationNum=12&fps=1   

2.event  
https://blog.csdn.net/windeal3203/article/details/52770759   

3.testRTSPClient建立RTSP连接的过程（RTSP客户端）  
https://www.cnblogs.com/jqctop1/p/4396301.html   


UsageEnvironment目录，生成的静态库为libUsageEnvironment.lib，这个库主要包含一些基本数据结构以及工具类的定义
groupsock目录，生成的静态库为libgroupsock.lib，这个库主要包含网络相关类的定义和实现
liveMedia目录，生成的静态库为libliveMedia.lib，这个库包含了Live555核心功能的实现
BasicUsageEnvironment目录，生成的静态库为libBasicUsageEnvironment.lib，这个库主要包含对UsageEnvironment库中一些类的实现

### continueAfterDESCRIBE函数的流程
#### continueAfterDESCRIBE函数的流程  

<img src="./image/6-2.png" style="zoom:100%" />

>注： session = MediaSession::createNew(*env, sdpDescription); //MediaSession类似于个个容器、链表用来管理MediaSubsession。  
在创建MediaSession的时候，顺便根据SDP信息中的m=部分创建了一个MediaSubsession对象。  
// We have a “m=” line, representing a new sub-session:  
MediaSubsession* subsession = createNewMediaSubsession();  
```c++
这里面重点说一下initiate函数  
subsession->initiate(simpleRTPoffsetArg)  
先根据sdp信息协商，采用UDP传输方式,创建两个Groupsock对象用于RTP/RTCP的接收，fRTPSocket，fRTCPSocket.  
之后在创建source，“fRTPSource”and “fReadSource”，和live555服务端原理一样，source和sink，分管生产和消费。  
createSourceObjects();  
这里根据返回的SDP信息创建对应的source，我这边是H264视频源，所以
 } else if (strcmp(fCodecName, "H264") == 0) {
    fReadSource = fRTPSource
      = H264VideoRTPSource::createNew(env(), fRTPSocket,
                      fRTPPayloadFormat,
                      fRTPTimestampFrequency);
      } 
然后创建一个fRTCPInstance = RTCPInstance::createNew，如果是多录视频fRTCPInstance 专门接受RTCP包，

基本上初始化工作已经完成了。但是疑问是我们接受server端发送的rtp包的前提，我们必须要监听一个端口才行啊。其实这一步是放在创建fRTPSocket，fRTCPSocket.的时候就完成了。
new Groupsock()->OutputSocket(env,port)->Socket(env,port)->setupDatagramSocket(fEnv,port)->bind ;
```

总结一下，获取SDP信息之后，我们干了哪些事。  
1.创建MediaSession MediaSubsession  
2.创建套接字fRTPSocket，fRTCPSocket.  
3.bind接收端口，为后面做准备  
4.初始化一个大的接收buffer  
5.创建source  
6.创建RTCPInstance  

<img src="./image/6-3.jpg" style="zoom:100%" />

#### testRTSPClient建立RTSP连接的过程（RTSP客户端）  
参考链接：  
https://www.cnblogs.com/lidabo/p/4483524.html   

https://www.cnblogs.com/freezlz/p/5324220.html   

1.live555 env->taskScheduler().doEventLoop()解析/自己实现  
https://blog.csdn.net/zhangjikuan/article/details/38403401

以testRTSPClient.cpp为例讲解：   
Medium<-MediaSource<-FramedSource<-RTPSource<-MultiFramedRTPSource<-H264VideoRTPSource   
其中，我们要重点关注的类是下面几个：   
FramedSource,RTPSource,MultiFramedRTPSource。   

#### VLC对Live555 RTSP视频直播稳定性问题
参考链接：  
1.vlc  
http://www.itnotepad.cn/Home/Article/num/60.html  
2.vlc包  
http://ftp.icm.edu.pl/packages/videolan/  
3.vlc相关问题  
https://www.xuebuyuan.com/2080121.html  

若使用live555做为网络直播流媒体服务，当网络延迟造成播放速度快于流下载的速度，即doGetNextFrame函数调用时流还没有传输过来；此时，用户需要增加延迟N毫秒执行任务，不能直接return返回；否则公网/内网播放是很容易中断的（不是立即断，所以是很多人长时间纠结也不容易发现中断的原因），同时也会造成崩溃情况。   
总的来说：doGetNextFrame当没流时，不能直接return，一定要加延迟执行 。也不能什么 都不处理，直接让执行到函数中末尾FramedSource::afterGetting(this)代码（很容易崩溃）;  
```c
下面列出关键延迟执行代码（来自网络开发人员启发）
定义延迟执行回调函数
void LiveStreamSource::GetNextFrame(void* clientData)
{
 LiveStreamSource* obj=(LiveStreamSource*)clientData;
 if(obj!=NULL)
 {
  if (!obj->isCurrentlyAwaitingData()) return;
  obj->doGetNextFrame();
 }
}
接着，在doGetNextFrame函数中视具体情况适当位置增加
void LiveStreamSource::doGetNextFrame() {
//TODO 其他代
if(xxx)
{
  delayTask=envir().taskScheduler().scheduleDelayedTask(30000,GetNextFrame,this);//没数据延迟30毫秒
return;
}
//TODO 其他代码
}
```
 
 

continuePlaying()函数中调用Source类（以MultiFramedRTPSource为例，因为它以实现doGetFrame()函数）的getNextFrame()函数以得到发送数据，而getNextFrame()是通过调用doGetNextFrame()，继而是doGetNextFrame1()，最终在doNextFrame1中由语句fReorderingBuffer->getNextCompletedPacket()将存放在fReorderingBuffer中的数据取出交给Sink类来发送。

3.1分析live555客户端解析play等命令流程 
首先RTSPClient 新建一个createNew，RTSPClient.cpp/RTSPClient 调用taskScheduler，新建task绑定incomingDataHandler，到handleResponseBytes，到handlePLAYResponse，等待接受到发送的play发送响应。具体rtsp交互流程可查看rtsp中相关章节。
2.2 rtsp时间戳计算方法
Rtsp的拖放和快放、慢放都是先pause，再play，根据play消息包中的range和scale参数来实现。
对应到live555中，pause时调用sendPauseCommand函数。Play时调用unsigned sendPlayCommand(MediaSubsession& subsession, responseHandler* responseHandler,double start = 0.0f, double end = -1.0f, float scale = 1.0f, Authenticator*authenticator = NULL)，在该函数中可以设置start，end（对应range，以秒为单位）和scale（对应快慢放）。end设为-1表示播放到文件结尾。在pause后的resume播放时，start可以设为-1，表示继续从当前位置播放；在seek时，start设为拖放到的播放时间点（以秒为单位）。
rtsp客户端对于每个收到的rtp数据包，可以根据时间戳调用doubleMediaSubsession::getNormalPlayTime(struct timeval const& presentationTime)获得当前相对文件开始（从0起始）的播放时间（秒）。
该函数的计算公式为：PlayStartTime+(currnpt-startnpt)*scale
PlayStartTIme：从收到服务器play应答中的range域中提取。
Currnpt：当前rtp包的时间戳
Startnpt：play后收到的第一个数据包的npt。
rtspserver中的rtp包时间戳实现：
每收到一个play请求后（seek和resume的play请求同样如此），取当前时间作为时间戳。以后每个数据包的时间戳计算公式为：play后第一个包的时间戳+当前包与第一个包在文件中的相对时间间隔。注意在Play的响应包中音视频的seq和rtptime分别要取pause时的值，否则客户端的时间条指示会不对。
在live555的rtspserver中，收到resume的play请求时（range域start为-1），返回的应答包不会置range域start时间，导致客户端提取PlayStartTIme为0。为了避免这种问题，客户端在resume的play请求中最好置start为当前播放时间，这样其实类似于seek操作了。
在读取文件结束时（音频或视频结束），构造RTCP  BYE包，通过RTCP通道往客户端发送一个BYE包，客户端会结束播放。

## links
  * [目录](<音视频入门到精通目录.md>)